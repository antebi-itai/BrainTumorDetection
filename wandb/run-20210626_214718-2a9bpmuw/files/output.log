|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  545997 KB |  545997 KB |  545997 KB |       0 B  |
|       from large pool |  544128 KB |  544128 KB |  544128 KB |       0 B  |
|       from small pool |    1869 KB |    1869 KB |    1869 KB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |  545997 KB |  545997 KB |  545997 KB |       0 B  |
|       from large pool |  544128 KB |  544128 KB |  544128 KB |       0 B  |
|       from small pool |    1869 KB |    1869 KB |    1869 KB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  571392 KB |  571392 KB |  571392 KB |       0 B  |
|       from large pool |  569344 KB |  569344 KB |  569344 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25394 KB |   26229 KB |   66425 KB |   41030 KB |
|       from large pool |   25216 KB |   25216 KB |   64384 KB |   39168 KB |
|       from small pool |     178 KB |    2041 KB |    2041 KB |    1862 KB |
|---------------------------------------------------------------------------|
| Allocations           |      39    |      39    |      39    |       0    |
|       from large pool |      14    |      14    |      14    |       0    |
|       from small pool |      25    |      25    |      25    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |      39    |      39    |      39    |       0    |
|       from large pool |      14    |      14    |      14    |       0    |
|       from small pool |      25    |      25    |      25    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       8    |       8    |       8    |       0    |
|       from large pool |       7    |       7    |       7    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       6    |       6    |       0    |
|       from large pool |       5    |       5    |       5    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|===========================================================================|
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  578765 KB |  672461 KB |     851 MB |  293345 KB |
|       from large pool |  576896 KB |  665984 KB |     843 MB |  286597 KB |
|       from small pool |    1869 KB |    7032 KB |       8 MB |    6748 KB |
|---------------------------------------------------------------------------|
| Active memory         |  578765 KB |  672461 KB |     851 MB |  293345 KB |
|       from large pool |  576896 KB |  665984 KB |     843 MB |  286597 KB |
|       from small pool |    1869 KB |    7032 KB |       8 MB |    6748 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  698368 KB |  698368 KB |  698368 KB |       0 B  |
|       from large pool |  690176 KB |  690176 KB |  690176 KB |       0 B  |
|       from small pool |    8192 KB |    8192 KB |    8192 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25394 KB |   29233 KB |  196337 KB |  170942 KB |
|       from large pool |   25216 KB |   29055 KB |  183551 KB |  158335 KB |
|       from small pool |     178 KB |    2226 KB |   12786 KB |   12607 KB |
|---------------------------------------------------------------------------|
| Allocations           |      41    |      73    |      89    |      48    |
|       from large pool |      16    |      32    |      44    |      28    |
|       from small pool |      25    |      42    |      45    |      20    |
|---------------------------------------------------------------------------|
| Active allocs         |      41    |      73    |      89    |      48    |
|       from large pool |      16    |      32    |      44    |      28    |
|       from small pool |      25    |      42    |      45    |      20    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      17    |      17    |      17    |       0    |
|       from large pool |      13    |      13    |      13    |       0    |
|       from small pool |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       8    |      27    |      21    |
|       from large pool |       5    |       6    |      16    |      11    |
|       from small pool |       1    |       4    |      11    |      10    |
|===========================================================================|
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  578765 KB |  672461 KB |     851 MB |  293346 KB |
|       from large pool |  576896 KB |  665984 KB |     843 MB |  286597 KB |
|       from small pool |    1869 KB |    7032 KB |       8 MB |    6749 KB |
|---------------------------------------------------------------------------|
| Active memory         |  578765 KB |  672461 KB |     851 MB |  293346 KB |
|       from large pool |  576896 KB |  665984 KB |     843 MB |  286597 KB |
|       from small pool |    1869 KB |    7032 KB |       8 MB |    6749 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  698368 KB |  698368 KB |  698368 KB |       0 B  |
|       from large pool |  690176 KB |  690176 KB |  690176 KB |       0 B  |
|       from small pool |    8192 KB |    8192 KB |    8192 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25394 KB |   29233 KB |  196338 KB |  170943 KB |
|       from large pool |   25216 KB |   29055 KB |  183551 KB |  158335 KB |
|       from small pool |     178 KB |    2226 KB |   12787 KB |   12608 KB |
|---------------------------------------------------------------------------|
| Allocations           |      41    |      73    |      91    |      50    |
|       from large pool |      16    |      32    |      44    |      28    |
|       from small pool |      25    |      42    |      47    |      22    |
|---------------------------------------------------------------------------|
| Active allocs         |      41    |      73    |      91    |      50    |
|       from large pool |      16    |      32    |      44    |      28    |
|       from small pool |      25    |      42    |      47    |      22    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      17    |      17    |      17    |       0    |
|       from large pool |      13    |      13    |      13    |       0    |
|       from small pool |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       8    |      28    |      22    |
|       from large pool |       5    |       6    |      16    |      11    |
|       from small pool |       1    |       4    |      12    |      11    |
|===========================================================================|
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(69)generate_heatmap()
     67         print(torch.cuda.memory_summary())
     68         import pdb; pdb.set_trace()
---> 69         heatmap = []
     70         for idx, images in occluded_loader:
     71           occluded_images = images.to(device=self.device)
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(70)generate_heatmap()
     68         import pdb; pdb.set_trace()
     69         heatmap = []
---> 70         for idx, images in occluded_loader:
     71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(71)generate_heatmap()
     69         heatmap = []
     70         for idx, images in occluded_loader:
---> 71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
     73           self.model(occluded_images)
tensor([0])
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],
         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],
         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
torch.Size([1, 3, 256, 256])
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(73)generate_heatmap()
     71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
---> 73           self.model(occluded_images)
     74
     75         features = fe.flush_activations()
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],
         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],
         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
device(type='cpu')
*** NameError: name 'sefl' is not defined
device(type='cuda', index=0)
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(70)generate_heatmap()
     68         import pdb; pdb.set_trace()
     69         heatmap = []
---> 70         for idx, images in occluded_loader:
     71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
*** SyntaxError: unmatched ')'
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  595918 KB |  705998 KB |    1170 MB |  602564 KB |
|       from large pool |  593280 KB |  698752 KB |    1154 MB |  589067 KB |
|       from small pool |    2638 KB |    7800 KB |      15 MB |   13497 KB |
|---------------------------------------------------------------------------|
| Active memory         |  595918 KB |  705998 KB |    1170 MB |  602564 KB |
|       from large pool |  593280 KB |  698752 KB |    1154 MB |  589067 KB |
|       from small pool |    2638 KB |    7800 KB |      15 MB |   13497 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  724992 KB |  724992 KB |  724992 KB |       0 B  |
|       from large pool |  716800 KB |  716800 KB |  716800 KB |       0 B  |
|       from small pool |    8192 KB |    8192 KB |    8192 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   30770 KB |   34866 KB |  350162 KB |  319392 KB |
|       from large pool |   29312 KB |   33408 KB |  327811 KB |  298499 KB |
|       from small pool |    1458 KB |    2226 KB |   22351 KB |   20893 KB |
|---------------------------------------------------------------------------|
| Allocations           |      44    |      77    |     143    |      99    |
|       from large pool |      17    |      34    |      74    |      57    |
|       from small pool |      27    |      44    |      69    |      42    |
|---------------------------------------------------------------------------|
| Active allocs         |      44    |      77    |     143    |      99    |
|       from large pool |      17    |      34    |      74    |      57    |
|       from small pool |      27    |      44    |      69    |      42    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      18    |      18    |      18    |       0    |
|       from large pool |      14    |      14    |      14    |       0    |
|       from small pool |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       8    |      10    |      49    |      41    |
|       from large pool |       6    |       7    |      29    |      23    |
|       from small pool |       2    |       5    |      20    |      18    |
|===========================================================================|
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(71)generate_heatmap()
     69         heatmap = []
     70         for idx, images in occluded_loader:
---> 71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
     73           self.model(occluded_images)
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(73)generate_heatmap()
     71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
---> 73           self.model(occluded_images)
     74
     75         features = fe.flush_activations()
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(70)generate_heatmap()
     68         import pdb; pdb.set_trace()
     69         heatmap = []
---> 70         for idx, images in occluded_loader:
     71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  613070 KB |  723150 KB |    1489 MB |     890 MB |
|       from large pool |  609664 KB |  715136 KB |    1466 MB |     870 MB |
|       from small pool |    3406 KB |    8569 KB |      23 MB |      19 MB |
|---------------------------------------------------------------------------|
| Active memory         |  613070 KB |  723150 KB |    1489 MB |     890 MB |
|       from large pool |  609664 KB |  715136 KB |    1466 MB |     870 MB |
|       from small pool |    3406 KB |    8569 KB |      23 MB |      19 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  727040 KB |  727040 KB |  727040 KB |       0 B  |
|       from large pool |  716800 KB |  716800 KB |  716800 KB |       0 B  |
|       from small pool |   10240 KB |   10240 KB |   10240 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   34097 KB |   45585 KB |  506731 KB |  472633 KB |
|       from large pool |   33408 KB |   43648 KB |  474625 KB |  441217 KB |
|       from small pool |     689 KB |    2226 KB |   32106 KB |   31416 KB |
|---------------------------------------------------------------------------|
| Allocations           |      47    |      80    |     195    |     148    |
|       from large pool |      18    |      35    |     104    |      86    |
|       from small pool |      29    |      46    |      91    |      62    |
|---------------------------------------------------------------------------|
| Active allocs         |      47    |      80    |     195    |     148    |
|       from large pool |      18    |      35    |     104    |      86    |
|       from small pool |      29    |      46    |      91    |      62    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      19    |      19    |      19    |       0    |
|       from large pool |      14    |      14    |      14    |       0    |
|       from small pool |       5    |       5    |       5    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |      11    |      73    |      64    |
|       from large pool |       7    |       8    |      44    |      37    |
|       from small pool |       2    |       5    |      29    |      27    |
|===========================================================================|
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(71)generate_heatmap()
     69         heatmap = []
     70         for idx, images in occluded_loader:
---> 71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
     73           self.model(occluded_images)
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(73)generate_heatmap()
     71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
---> 73           self.model(occluded_images)
     74
     75         features = fe.flush_activations()
> /home/labs/waic/itaian/BrainTumorDetection/experiment.py(70)generate_heatmap()
     68         import pdb; pdb.set_trace()
     69         heatmap = []
---> 70         for idx, images in occluded_loader:
     71           occluded_images = images.to(device=self.device)
     72           # Run the model on batched occluded images
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  630223 KB |  740303 KB |    1807 MB |    1192 MB |
|       from large pool |  626048 KB |  731520 KB |    1777 MB |    1166 MB |
|       from small pool |    4175 KB |    9337 KB |      30 MB |      26 MB |
|---------------------------------------------------------------------------|
| Active memory         |  630223 KB |  740303 KB |    1807 MB |    1192 MB |
|       from large pool |  626048 KB |  731520 KB |    1777 MB |    1166 MB |
|       from small pool |    4175 KB |    9337 KB |      30 MB |      26 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  768000 KB |  768000 KB |  768000 KB |       0 B  |
|       from large pool |  757760 KB |  757760 KB |  757760 KB |       0 B  |
|       from small pool |   10240 KB |   10240 KB |   10240 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   39473 KB |   49713 KB |  628809 KB |  589336 KB |
|       from large pool |   37504 KB |   47744 KB |  587651 KB |  550147 KB |
|       from small pool |    1969 KB |    2226 KB |   41158 KB |   39189 KB |
|---------------------------------------------------------------------------|
| Allocations           |      50    |      83    |     247    |     197    |
|       from large pool |      19    |      36    |     134    |     115    |
|       from small pool |      31    |      48    |     113    |      82    |
|---------------------------------------------------------------------------|
| Active allocs         |      50    |      83    |     247    |     197    |
|       from large pool |      19    |      36    |     134    |     115    |
|       from small pool |      31    |      48    |     113    |      82    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      21    |      21    |      21    |       0    |
|       from large pool |      16    |      16    |      16    |       0    |
|       from small pool |       5    |       5    |       5    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      11    |      13    |      94    |      83    |
|       from large pool |       8    |       9    |      57    |      49    |
|       from small pool |       3    |       5    |      37    |      34    |
|===========================================================================|
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (26): ReLU(inplace=True)
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): ReLU(inplace=True)
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=2, bias=True)
  )
)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))